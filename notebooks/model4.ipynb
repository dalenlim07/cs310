{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0d04e8-d628-4d66-8ed2-6534e0623ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9c75cc-98b6-49cd-84ba-9d6ae18d877c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    img_highres/Sheer_Pleated-Front_Blouse/img_000...\n",
      "1    img_highres/Sheer_Pleated-Front_Blouse/img_000...\n",
      "2    img_highres/Sheer_Pleated-Front_Blouse/img_000...\n",
      "3    img_highres/Sheer_Pleated-Front_Blouse/img_000...\n",
      "4    img_highres/Sheer_Pleated-Front_Blouse/img_000...\n",
      "Name: image_name, dtype: object\n",
      "0    img_highres/Striped_Denim_Shorts/img_00000037.jpg\n",
      "1       img_highres/Rose_Print_Shorts/img_00000058.jpg\n",
      "2    img_highres/Embroidered_High-Neck_Blouse/img_0...\n",
      "3     img_highres/Tie-Dye_Cami_Romper/img_00000001.jpg\n",
      "4    img_highres/Favorite_Scoop_Neck_Tank/img_00000...\n",
      "Name: image_name, dtype: object\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/Category_and_Attribute_Prediction_Benchmark'\n",
    "\n",
    "# Load category annotations\n",
    "category_img = pd.read_csv('../data/Category_and_Attribute_Prediction_Benchmark/Anno_coarse/list_category_img.txt', sep='\\s+', skiprows=2, header=None)\n",
    "category_img.columns = ['image_name', 'category_label']\n",
    "\n",
    "# Load category names\n",
    "category_names = pd.read_csv('../data/Category_and_Attribute_Prediction_Benchmark/Anno_coarse/list_category_cloth.txt', sep='\\s+', skiprows=1, header=None)\n",
    "category_names.columns = ['category_name', 'category_type']\n",
    "\n",
    "# Load attribute names \n",
    "attribute_names = pd.read_csv('../data/Category_and_Attribute_Prediction_Benchmark/Anno_fine/list_attr_cloth.txt', sep='\\s+', skiprows=1, header=None)\n",
    "attribute_names.columns = ['attribute_name', 'attribute_type']\n",
    "\n",
    "# Merge category names with image annotations\n",
    "category_img = category_img.merge(category_names, left_on='category_label', right_index=True)\n",
    "\n",
    "# Load attribute annotations\n",
    "attr_img = pd.read_csv('../data/Category_and_Attribute_Prediction_Benchmark/Anno_fine/list_attr_img_update.txt', sep='\\s+', skiprows=2, header=None)\n",
    "attr_img.columns = ['image_name'] + [f'attr_{i+1}' for i in range(attr_img.shape[1] - 1)]\n",
    "\n",
    "category_img['image_name'] = category_img['image_name'].str.replace('img/', 'img_highres/')\n",
    "attr_img['image_name'] = attr_img['image_name'].str.replace('img_highres_subset/', 'img_highres/')\n",
    "\n",
    "print(category_img['image_name'].head())\n",
    "print(attr_img['image_name'].head())\n",
    "\n",
    "# Merge with category data\n",
    "dataset = pd.merge(category_img, attr_img, on='image_name')\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26931d79-d71d-40be-ba88-94f0541e9062",
   "metadata": {},
   "source": [
    "# Subset the Dataset from list_eval_partition.txt\n",
    "Split them into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0a8643-5c5d-4901-baa7-fd341d30500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 12002\n",
      "Validation samples: 2001\n",
      "Testing samples: 5997\n"
     ]
    }
   ],
   "source": [
    "# Sample a subset of the dataset\n",
    "eval_partition = pd.read_csv(f'{base_dir}/Eval/list_eval_partition.txt', sep='\\s+', skiprows=2, header=None)\n",
    "eval_partition.columns = ['image_name', 'evaluation_status']\n",
    "\n",
    "eval_partition['image_name'] = eval_partition['image_name'].str.replace('img/', 'img_highres/')\n",
    "\n",
    "# Merge evaluation partition with dataset\n",
    "dataset = pd.merge(dataset, eval_partition, on='image_name')\n",
    "\n",
    "# Split into train, val, and test datasets\n",
    "train_data = dataset[dataset['evaluation_status'] == 'train']\n",
    "val_data = dataset[dataset['evaluation_status'] == 'val']\n",
    "test_data = dataset[dataset['evaluation_status'] == 'test']\n",
    "\n",
    "# Print the lengths of each dataset for verification\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Testing samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9733aa5-90ea-4848-b0f9-f5977fed7135",
   "metadata": {},
   "source": [
    "## Split training data into 8 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f49e1592-b04b-48b0-a4e6-42f08de2a5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalenlim/cs310/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Split into 8 chunks\n",
    "chunks = np.array_split(train_data, 8)\n",
    "\n",
    "# ImageDataGenerator setup\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Define the model\n",
    "def create_xception_model(num_attributes):\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Category output\n",
    "    category_output = Dense(len(category_names), activation='softmax', name='category_output')(x)\n",
    "\n",
    "    # Attribute output\n",
    "    attribute_output = Dense(num_attributes, activation='sigmoid', name='attribute_output')(x)\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs=base_model.input, outputs=[category_output, attribute_output])\n",
    "\n",
    "    # Compile with SGD optimizer\n",
    "    optimizer = SGD(learning_rate=1e-4, momentum=0.9)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={\n",
    "            'category_output': 'categorical_crossentropy',\n",
    "            'attribute_output': 'binary_crossentropy',\n",
    "        },\n",
    "        metrics={\n",
    "            'category_output': 'accuracy',\n",
    "            'attribute_output': 'accuracy',\n",
    "        },\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71084a95-5e57-42b8-8a25-41111c939bf8",
   "metadata": {},
   "source": [
    "# Pre-train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce232c7-c2d3-483b-9dee-13db38a7d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "class MultiOutputDataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, directory, x_col, y_cols, batch_size, target_size):\n",
    "        self.dataframe = dataframe\n",
    "        self.directory = directory\n",
    "        self.x_col = x_col\n",
    "        self.y_cols = y_cols\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.indexes = np.arange(len(dataframe))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the batch indices\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Get the batch dataframe\n",
    "        batch_data = self.dataframe.iloc[batch_indexes]\n",
    "\n",
    "        # Process the inputs and outputs\n",
    "        X, y_category, y_attributes = [], [], []\n",
    "        for _, row in batch_data.iterrows():\n",
    "            # Load and preprocess the image\n",
    "            img_path = f\"{self.directory}/{row[self.x_col]}\"\n",
    "            img = load_img(img_path, target_size=self.target_size)\n",
    "            img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "            X.append(img)\n",
    "            \n",
    "            # Extract labels\n",
    "            y_category.append(row['category_label'])\n",
    "            y_attributes.append(row[self.y_cols].values.astype(float))\n",
    "        \n",
    "        # Convert to NumPy arrays\n",
    "        X = np.array(X)\n",
    "        y_category = tf.keras.utils.to_categorical(y_category, num_classes=len(category_names))\n",
    "        y_attributes = np.array(y_attributes)\n",
    "\n",
    "        return X, {'category_output': y_category, 'attribute_output': y_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65aebe13-8f13-4cb9-bbb3-5d0bca4422c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Pre-training on chunk 1/8\n",
      "Common classes: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalenlim/cs310/venv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 26), output.shape=(None, 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Create and train the model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m create_xception_model(num_attributes)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Save weights after training each chunk\u001b[39;00m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxception_weights_chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/cs310/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/cs310/venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/nn.py:701\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[0;32m--> 701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    702\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    707\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[1;32m    708\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m )\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 26), output.shape=(None, 51)"
     ]
    }
   ],
   "source": [
    "# Define columns for labels\n",
    "attribute_cols = [f'attr_{i+1}' for i in range(attr_img.shape[1] - 1)]\n",
    "\n",
    "# Number of attributes\n",
    "num_attributes = len(attribute_cols)\n",
    "\n",
    "print(num_attributes)\n",
    "\n",
    "# Pre-train on each chunk for 15 epochs\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Pre-training on chunk {i+1}/8\")\n",
    "\n",
    "    train_classes = set(chunk['category_name'])\n",
    "    val_classes = set(val_data['category_name'])\n",
    "\n",
    "    common_classes = train_classes.intersection(val_classes)\n",
    "    print(f\"Common classes: {len(common_classes)}\")\n",
    "\n",
    "    # Filter datasets to include only common classes\n",
    "    chunk = chunk[chunk['category_name'].isin(common_classes)]\n",
    "    val_data = val_data[val_data['category_name'].isin(common_classes)]\n",
    "    \n",
    "    # Create custom training generator\n",
    "    train_gen = MultiOutputDataGenerator(\n",
    "        dataframe=chunk,\n",
    "        directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "        x_col='image_name',\n",
    "        y_cols=attribute_cols,\n",
    "        batch_size=32,\n",
    "        target_size=(100, 100)\n",
    "    )\n",
    "    \n",
    "    # Create custom validation generator\n",
    "    val_gen = MultiOutputDataGenerator(\n",
    "        dataframe=val_data,\n",
    "        directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "        x_col='image_name',\n",
    "        y_cols=attribute_cols,\n",
    "        batch_size=64,\n",
    "        target_size=(100, 100)\n",
    "    )\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_xception_model(num_attributes)\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=15,\n",
    "        steps_per_epoch=len(train_gen),\n",
    "        validation_steps=len(val_gen)\n",
    "    )\n",
    "    \n",
    "    # Save weights after training each chunk\n",
    "    model.save_weights(f\"xception_weights_chunk_{i+1}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fdf8a1f-2291-4990-aa51-dc0fee54365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training on chunk 1/8\n",
      "Found 1501 validated image filenames.\n",
      "Found 2001 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dalenlim/cs310/venv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create and train the model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m create_xception_model()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Save weights after training each chunk\u001b[39;00m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxception_weights_chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/cs310/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/cs310/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py:124\u001b[0m, in \u001b[0;36m_from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_signature):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, type_spec\u001b[38;5;241m.\u001b[39mTypeSpec):\n\u001b[0;32m--> 124\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`output_signature` must contain objects that are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclass of `tf.TypeSpec` but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m output_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not."
     ]
    }
   ],
   "source": [
    "# Pre-train on each chunk for 15 epochs\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Pre-training on chunk {i+1}/8\")\n",
    "    \n",
    "    # Prepare the target columns for multi-output\n",
    "    y_columns = ['category_label'] + [f'attr_{i+1}' for i in range(attr_img.shape[1] - 1)]\n",
    "\n",
    "    # Ensure targets are included as separate columns in the generator\n",
    "    chunk_targets = chunk[y_columns].copy()\n",
    "    \n",
    "    # Data generator for the current chunk\n",
    "    train_gen = datagen.flow_from_dataframe(\n",
    "        dataframe=chunk,\n",
    "        directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "        x_col='image_name',\n",
    "        y_col=y_columns,\n",
    "        target_size=(100, 100),\n",
    "        batch_size=32,\n",
    "        class_mode='multi_output'\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "        x_col='image_name',\n",
    "        y_col=y_columns,\n",
    "        target_size=(100, 100),\n",
    "        batch_size=64,\n",
    "        class_mode='multi_output'\n",
    "    )\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_xception_model()\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=15,\n",
    "        steps_per_epoch=len(train_gen),\n",
    "        validation_steps=len(val_gen)\n",
    "    )\n",
    "    \n",
    "    # Save weights after training each chunk\n",
    "    model.save_weights(f\"xception_weights_chunk_{i+1}.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119df52e-5ba3-44bd-bf63-82c2e3241f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select one chunk\n",
    "selected_chunk_idx = random.randint(0, 7)\n",
    "selected_chunk = chunks[selected_chunk_idx]\n",
    "print(f\"Selected chunk: {selected_chunk_idx + 1}\")\n",
    "\n",
    "# Train the model on the selected chunk for 100 epochs\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=selected_chunk,\n",
    "    directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "    x_col='image_name',\n",
    "    y_col=['category_label'] + [f'attr_{i+1}' for i in range(attr_img.shape[1] - 1)],\n",
    "    target_size=(100, 100),\n",
    "    batch_size=64,\n",
    "    class_mode='multi_output'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "    x_col='image_name',\n",
    "    y_col=['category_label'] + [f'attr_{i+1}' for i in range(attr_img.shape[1] - 1)],\n",
    "    target_size=(100, 100),\n",
    "    batch_size=64,\n",
    "    class_mode='multi_output'\n",
    ")\n",
    "    \n",
    "model = create_xception_model()\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen)\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save('xception_final_model.weights.h5')\n",
    "\n",
    "# Evaluate on test data\n",
    "test_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    directory='../data/Category_and_Attribute_Prediction_Benchmark/Img/',\n",
    "    x_col='image_name',\n",
    "    y_col=['category_label'] + [f'attr_{i+1}' for i in range(attr_img.shape[1] - 1)],\n",
    "    target_size=(100, 100),\n",
    "    batch_size=64,\n",
    "    class_mode='multi_output'\n",
    ")\n",
    "\n",
    "test_results = model.evaluate(test_gen, steps=len(test_gen))\n",
    "print(f\"Test Results: {test_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
